model:
  model_name: "lorea-asr-1" 

training:
  epochs: 5
  batch_size: 8
  learning_rate: 3e-4

logging:
  save_checkpoint_every: 1 
  checkpoint_dir: "./checkpoints"