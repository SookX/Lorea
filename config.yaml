model:
  model_name: "lorea-asr-3" 

training:
  epochs: 80
  batch_size: 4
  learning_rate: 1e-4

logging:
  save_checkpoint_every: 1 
  checkpoint_dir: "./checkpoints"